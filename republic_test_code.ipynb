{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af1dc9d1",
   "metadata": {},
   "source": [
    "# Create the code to test REPUBLIC with lots of PLATO-like light curves\n",
    "##### Oscar Barrag√°n, Nov 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the libraries\n",
    "from __future__ import division, absolute_import, print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from matplotlib import gridspec\n",
    "#Be sure you have citlalicue installed, if not, install it with\n",
    "#pip install citlalicue\n",
    "from citlalicue.citlalicue import citlali\n",
    "#The republic module is inside this directory\n",
    "import republic\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE THE MULTICAMERA CONFIGURATION HERE\n",
    "#I create the data set for 24 cameras, but later it can be changed to \n",
    "#run with less cameras taking subsets of the 24 cameras array\n",
    "J = 24  # number of cameras\n",
    "N = 4    # number of trends per camera\n",
    "K = 1000 # number of observations\n",
    "N_lcs = 1000 #Number of light curves\n",
    "kepler_quarter = 10 #Select the Kepler quarter that we are using to obtain the Cotrending Basis Vectors\n",
    "t = np.linspace(0,90,K)  #Time span to simulate the observations\n",
    "np.random.seed(1) #Random seed to ensure reproducibility between different runs of this code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05ed8a",
   "metadata": {},
   "source": [
    "## Let us create the light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8e9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ranges to create the light curves\n",
    "\n",
    "#QP kernel hyper parameters\n",
    "Amps = [1e-5,5e-3]\n",
    "les  = [10,1000]\n",
    "lps  = [0.1,2]\n",
    "Pgps = [3,30]\n",
    "\n",
    "#Planet parameters\n",
    "t0s  = [0,5]\n",
    "Ps   = [0,10]\n",
    "bs   = [0,1]\n",
    "ars  = [1.5,50]\n",
    "rps  = [0.01,0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d37734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the light curves\n",
    "#lcs is a list that contain all the light curve objects\n",
    "lcs = [None]*N_lcs\n",
    "for i in tqdm(range(N_lcs)):\n",
    "    #Let us create a light curve using citlalicue\n",
    "    lc = citlali(time=t) \n",
    "    #In this case, we just need to call the add_spots method\n",
    "    Amp = np.random.uniform(*Amps)\n",
    "    le  = np.random.uniform(*les)\n",
    "    lp  = np.random.uniform(*lps)\n",
    "    Pgp = np.random.uniform(*Pgps)\n",
    "    lc.add_spots(QP=[Amp,le,lp,Pgp])\n",
    "    T0 = np.random.uniform(*t0s)\n",
    "    P  = np.random.uniform(*Ps)\n",
    "    b  = np.random.uniform(*bs)\n",
    "    a  = np.random.uniform(*ars)\n",
    "    rp = np.random.uniform(*rps)\n",
    "    u1 = 0\n",
    "    u2 = 0\n",
    "    #Let us create a list with all the planet parameters\n",
    "    planet_parameters = [T0,P,b,a,rp,u1,u2]\n",
    "    #Let us add the planet by calling the add_transits method\n",
    "    lc.add_transits(planet_parameters=planet_parameters,planet_name='b')\n",
    "    #lc.plot(fsx=20,fsy=5)\n",
    "\n",
    "    #Let's store the current light curve instance in the master list\n",
    "    lcs[i] = lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a698607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that the instances have light curves\n",
    "lcs[9].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d7ae5f",
   "metadata": {},
   "source": [
    "## Time to create the trends that will mimic the camera-like systematics\n",
    "We are creating a master set with 24 cameras, and uncorrelated systatics, then using this we can easily create trends with correlated systematics and/or less cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5724a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us create the different sets of systematic treds\n",
    "#create_kepler_CBVs is a function inside republic.py\n",
    "T_master = republic.create_kepler_CBVs(t,quarter=kepler_quarter,N_cameras=J,ndata=K,N_trends=N,plot_cbvs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a plot with the systematics of different cameras\n",
    "fig = plt.figure(1,figsize=(15,10))\n",
    "gs = gridspec.GridSpec(nrows=3,ncols=2)\n",
    "gs.update(hspace=0.025)\n",
    "gs.update(wspace=0.01)\n",
    "cameras = [0,1,2,3,4,5]\n",
    "#\n",
    "for i,cam in enumerate(cameras):\n",
    "    plt.subplot(gs[i])\n",
    "    for j in range(N):\n",
    "        if i == 0:\n",
    "            plt.plot(t,T_master[cam,:,j],alpha=0.9,label='Trend '+str(j+1),lw=1)\n",
    "        else:\n",
    "            plt.plot(t,T_master[cam,:,j],alpha=0.9,lw=1)\n",
    "    if i == 0:\n",
    "        plt.legend(loc=1,ncols=4,frameon=True)\n",
    "    if i%gs.ncols != 0:\n",
    "        plt.tick_params(axis='y',labelleft=False,left=False)\n",
    "    else:\n",
    "        plt.ylabel('Value')\n",
    "    plt.xlabel('Time [days]')\n",
    "    plt.xlim(0.01,89.9)\n",
    "    plt.ylim(-0.59,0.59)\n",
    "\n",
    "out_file = 'trends.pdf'\n",
    "plt.savefig(out_file,bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d4d8c",
   "metadata": {},
   "source": [
    "## Time to platorize the light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEt us create the PLATO-like data for all cameras adding a new attribute to the lcs[i] instances\n",
    "#All stars will have the same trends\n",
    "sig = 0.0005\n",
    "for i in range(N_lcs):\n",
    "    lcs[i].plato = republic.platorize(lcs[i].flux,T_master,J,N,K,sig=sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa32a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot only one light curve to check that everything is OK\n",
    "plt.figure(figsize=(15,5))\n",
    "n = 0 #Let us plot the first light curve\n",
    "for i in range(J):\n",
    "    plt.plot(t,lcs[n].plato[i]-i*0.01,'.',alpha=0.3)\n",
    "plt.xlim(t.min(),t.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tests can be done with less light curves to make this notebook run faster\n",
    "N_l = 100\n",
    "#To run with the whole set of light curves uncomment the next line\n",
    "#N_l = N_lcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d954abb",
   "metadata": {},
   "source": [
    "## Let us correct the light curves using republic with 6, 12 and 24 cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run republic for all cameras\n",
    "for i in tqdm(range(N_l)):\n",
    "    #6 cameras\n",
    "    #Let us do the republic magic correcting with a different number of cameras each time\n",
    "    ncam=6\n",
    "    T_use = T_master[:ncam,:,:] \n",
    "    sigma = np.zeros((ncam,K)) + sig\n",
    "    lcs[i].a_6, lcs[i].w_6, lcs[i].B_6 = republic.republic_solve(lcs[i].plato[0:ncam], T_use, sigma)\n",
    "    #12 cameras\n",
    "    ncam=12\n",
    "    T_use = T_master[:ncam,:,:] \n",
    "    sigma = np.zeros((ncam,K)) + sig\n",
    "    lcs[i].a_12, lcs[i].w_12, lcs[i].B_12 = republic.republic_solve(lcs[i].plato[0:ncam], T_use, sigma)\n",
    "    #24 cameras\n",
    "    ncam=24\n",
    "    T_use = T_master[:ncam,:,:] \n",
    "    sigma = np.zeros((ncam,K)) + sig\n",
    "    lcs[i].a_24, lcs[i].w_24, lcs[i].B_24 = republic.republic_solve(lcs[i].plato[0:ncam], T_use, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = 5\n",
    "fig = plt.figure(1,figsize=(15,5),rasterized=True)\n",
    "plt.plot(lcs[nl].time,(lcs[nl].a_6 -lcs[nl].flux)*1e3,'.',label= '6 Cameras',lw=0.5)\n",
    "plt.plot(lcs[nl].time,(lcs[nl].a_12-lcs[nl].flux)*1e3,'.',label='12 Cameras',lw=0.5)\n",
    "plt.plot(lcs[nl].time,(lcs[nl].a_24-lcs[nl].flux)*1e3,'.',label='24 Cameras',lw=0.5)\n",
    "plt.ylabel('Residuals [ppt]')\n",
    "plt.xlabel('Time [days]')\n",
    "plt.legend(frameon=True)\n",
    "plt.xlim(t.min(),t.max())\n",
    "out_file = 'cameras_differences.pdf'\n",
    "plt.savefig(out_file,bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5e3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(lcs[nl].time,lcs[nl].a_6 ,'.',label='6')\n",
    "plt.plot(lcs[nl].time,lcs[nl].a_12+0.05,'.',label='12')\n",
    "plt.plot(lcs[nl].time,lcs[nl].a_24+0.09,'.',label='24')\n",
    "plt.xlim(t.min(),t.max())\n",
    "plt.legend(frameon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe8d79a",
   "metadata": {},
   "source": [
    "## LEt us test for light curves with different levels of white noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb240a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEt us create the PLATO-like data for all cameras adding a new attribute to the lcs[i] instances\n",
    "#All stars will have the same trends\n",
    "sig = 0.005\n",
    "for i in range(N_l):\n",
    "    lcs[i].plato_wn5ppt = republic.platorize(lcs[i].flux,T_master,J,N,K,sig=sig)\n",
    "#50 times more white noise\n",
    "sig = 0.025\n",
    "for i in range(N_l):\n",
    "    lcs[i].plato_wn25ppt = republic.platorize(lcs[i].flux,T_master,J,N,K,sig=sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(lcs[0].plato[0],'.')\n",
    "plt.plot(lcs[0].plato_wn5ppt[0],'.')\n",
    "plt.plot(lcs[0].plato_wn25ppt[0],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us correct the light curves with REPUBLIC\n",
    "#Run republic for all cameras\n",
    "for i in tqdm(range(N_l)):\n",
    "    #6 cameras\n",
    "    #Let us do the republic magic correcting with a different number of cameras each time\n",
    "    ncam=6\n",
    "    T_use = T_master[:ncam,:,:] \n",
    "    sig = 0.005\n",
    "    sigma = np.zeros((ncam,K)) + sig\n",
    "    lcs[i].a_6_wn5ppt, lcs[i].w_6_wn5ppt, lcs[i].B_6_wn5ppt = republic.republic_solve(lcs[i].plato_wn5ppt[0:ncam], T_use, sigma)\n",
    "    sig = 0.025\n",
    "    sigma = np.zeros((ncam,K)) + sig\n",
    "    lcs[i].a_6_wn25ppt, lcs[i].w_6_wn25ppt, lcs[i].B_6_wn25ppt = republic.republic_solve(lcs[i].plato_wn25ppt[0:ncam], T_use, sigma)\n",
    "    #12 cameras\n",
    "    ncam=12\n",
    "    T_use = T_master[:ncam,:,:] \n",
    "    sig = 0.005\n",
    "    sigma = np.zeros((ncam,K)) + sig\n",
    "    lcs[i].a_12_wn5ppt, lcs[i].w_12_wn5ppt, lcs[i].B_12_wn5ppt = republic.republic_solve(lcs[i].plato_wn5ppt[0:ncam], T_use, sigma)\n",
    "    sig = 0.025\n",
    "    sigma = np.zeros((ncam,K)) + sig\n",
    "    lcs[i].a_12_wn25ppt, lcs[i].w_12_wn25ppt, lcs[i].B_12_wn25ppt = republic.republic_solve(lcs[i].plato_wn25ppt[0:ncam], T_use, sigma)\n",
    "    #24 cameras\n",
    "    ncam=24\n",
    "    T_use = T_master[:ncam,:,:] \n",
    "    sig = 0.005\n",
    "    sigma = np.zeros((ncam,K)) + sig\n",
    "    lcs[i].a_24_wn5ppt, lcs[i].w_24_wn5ppt, lcs[i].B_24_wn5ppt = republic.republic_solve(lcs[i].plato_wn5ppt[0:ncam], T_use, sigma)\n",
    "    sig = 0.025\n",
    "    sigma = np.zeros((ncam,K)) + sig\n",
    "    lcs[i].a_24_wn25ppt, lcs[i].w_24_wn25ppt, lcs[i].B_24_wn25ppt = republic.republic_solve(lcs[i].plato_wn25ppt[0:ncam], T_use, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637756b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us compare the residuals for all the cases\n",
    "nlc = 0\n",
    "plt.figure(figsize=(15,5),rasterized=True)\n",
    "plt.plot(lcs[nlc].time,(lcs[nlc].a_24        -lcs[nlc].flux)*1e3,'.',color='C0',alpha=0.8,\n",
    "         zorder=2,label='original white noise = 0.5 ppt')\n",
    "plt.plot(lcs[nlc].time,(lcs[nlc].a_24_wn5ppt -lcs[nlc].flux)*1e3,'.',color='C1',alpha=0.8,\n",
    "         zorder=1,label='original white noise = 5 ppt')\n",
    "plt.plot(lcs[nlc].time,(lcs[nlc].a_24_wn25ppt-lcs[nlc].flux)*1e3,'.',color='C2',alpha=0.8,\n",
    "         zorder=0,label='original white noise = 25 ppt')\n",
    "#\n",
    "plt.xlim(lcs[nlc].time.min(),lcs[nlc].time.max())\n",
    "plt.legend(frameon=True,loc=1)\n",
    "\n",
    "plt.ylabel('Residuals [ppt]')\n",
    "plt.xlabel('Time [days]');\n",
    "out_file = 'whitenoise_differences.pdf'\n",
    "plt.savefig(out_file,bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c6ca61",
   "metadata": {},
   "source": [
    "## Let's correct the light curves with a PDC-LS-like algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3449e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#light curve by light curve\n",
    "for n in tqdm(range(N_l)):\n",
    "    lcs[n].pdcls = [None]*J\n",
    "    #camera by camera\n",
    "    for j in range(J):\n",
    "        #Let us shift the fluxes to zero to be able to do PDCLS \n",
    "        basis = np.array(T_master[j,:,:])\n",
    "        lcs[n].pdcls[j] = republic.PDCLS(lcs[n].plato[j]-np.mean(lcs[n].plato[j]),basis.T)\n",
    "    #Combine all the light curves \n",
    "    lcs[n].pdcls_mean = np.mean(lcs[n].pdcls,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ff1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(lcs[nlc].pdcls_mean-lcs[nlc].flux+np.mean(lcs[nlc].flux))\n",
    "plt.plot(lcs[nlc].a_24-lcs[nlc].flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a294eb",
   "metadata": {},
   "source": [
    "### Create the plot for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1,figsize=(14,17))\n",
    "gs = gridspec.GridSpec(nrows=4,ncols=1)\n",
    "gs.update(hspace=0.025)\n",
    "#\n",
    "plt.subplot(gs[0],rasterized=True)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].flux,'k-',label='True signal')\n",
    "plt.xlim(lcs[nlc].time.min(),lcs[nlc].time.max())\n",
    "plt.tick_params(axis='x', which='both', direction='in',labelbottom=False)\n",
    "plt.ylabel('Flux')\n",
    "plt.annotate('a)',(0.1,0.91),xycoords='subfigure fraction')\n",
    "#\n",
    "plt.subplot(gs[1],rasterized=True)\n",
    "for j in range(J):\n",
    "    if j == 0:\n",
    "        plt.plot(lcs[nlc].time,lcs[nlc].plato[j],'o',lw=0.75,alpha=.5, label = 'LC cameras',markersize=2)\n",
    "    else:\n",
    "        plt.plot(lcs[nlc].time,lcs[nlc].plato[j]-j*0.01,'o',lw=0.75,alpha=.5,markersize=2)\n",
    "plt.xlim(lcs[nlc].time.min(),lcs[nlc].time.max())\n",
    "plt.tick_params(axis='x', which='both', direction='in',labelbottom=False)\n",
    "plt.ylabel('Flux + offset')\n",
    "plt.annotate('b)',(0.1,0.7),xycoords='subfigure fraction')\n",
    "#\n",
    "plt.subplot(gs[2],rasterized=True)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].pdcls_mean+np.mean(lcs[nlc].flux),'C0.',label='PDCLS',alpha=0.75)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].a_24,'C1.',label='REPUBLIC',alpha=0.75)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].flux,'k-',label='True signal')\n",
    "plt.xlim(lcs[nlc].time.min(),lcs[nlc].time.max())\n",
    "plt.tick_params(axis='x', which='both', direction='in',labelbottom=False)\n",
    "plt.ylabel('Flux')\n",
    "plt.annotate('c)',(0.1,0.47),xycoords='subfigure fraction')\n",
    "#\n",
    "plt.subplot(gs[3],rasterized=True)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].pdcls_mean-lcs[nlc].flux+np.mean(lcs[nlc].flux),'C0.',\n",
    "         label='PDCLS $-$ True',alpha=0.75)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].a_24-lcs[nlc].flux,'C1.',label='REPUBLIC $-$ True',alpha=0.75)\n",
    "plt.xlim(lcs[nlc].time.min(),lcs[nlc].time.max())\n",
    "plt.tick_params(axis='x', which='both', direction='in',labelbottom=True)\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylabel('Residuals')\n",
    "plt.annotate('d)',(0.1,0.23),xycoords='subfigure fraction')\n",
    "out_file = 'lc.pdf'\n",
    "plt.savefig(out_file,bbox_inches='tight',dpi=300)\n",
    "#plt.savefig('republic-broken.png',bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655abc13",
   "metadata": {},
   "source": [
    "### Extract the trends with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc99608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us do a PCA for one single camera j\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "N_components = 4\n",
    "\n",
    "#Let us create an array to store the trends obtained with CBVs\n",
    "T_CBV = np.ones((J,K,N_components)) \n",
    "\n",
    "#Here we need all the light curve N_lcs (not N_l) to extract the best CBVs\n",
    "data = [None]*N_lcs\n",
    "\n",
    "#camera by camera\n",
    "for j in tqdm(range(J)):\n",
    "    #light curve by light curve\n",
    "    for i in range(N_lcs):\n",
    "        data[i] = lcs[i].plato[j]\n",
    "    #Now data has the information for all the light curves for a given camera\n",
    "    scaler = StandardScaler()\n",
    "    data_standardized = scaler.fit_transform(np.array(data).T)\n",
    "    #Apply PCA\n",
    "    pca = PCA()\n",
    "    pca_result = pca.fit_transform(data_standardized)\n",
    "    pca_components = PCA(n_components=N_components)\n",
    "    #extract the components\n",
    "    transformed_data = pca_components.fit_transform(data_standardized)\n",
    "    transformed_data_df = pd.DataFrame(transformed_data)\n",
    "    #Save the recovered PCA components in the T_CBV array to be used by republic\n",
    "    for k in range(N_components):\n",
    "        T_CBV[j,:,k] = transformed_data_df[k] \n",
    "        T_CBV[j,:,k] = (T_CBV[j,:,k] - T_CBV[j,:,k].min()) / (T_CBV[j,:,k].max() - T_CBV[j,:,k].min()) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182817f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us plot the extracted trends\n",
    "plt.figure(figsize=(15,5))\n",
    "for k in range(N_components):\n",
    "    plt.plot(T_CBV[0,:,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983536e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a plot with the systematics of different cameras\n",
    "fig = plt.figure(1,figsize=(15,10))\n",
    "gs = gridspec.GridSpec(nrows=3,ncols=2)\n",
    "gs.update(hspace=0.025)\n",
    "gs.update(wspace=0.01)\n",
    "cameras = [0,1,2,3,4,5]\n",
    "#\n",
    "for i,cam in enumerate(cameras):\n",
    "    plt.subplot(gs[i])\n",
    "    for j in range(N):\n",
    "        if i == 0:\n",
    "            plt.plot(t,T_CBV[cam,:,j],alpha=0.9,label='Trend '+str(j+1),lw=1)\n",
    "        else:\n",
    "            plt.plot(t,T_CBV[cam,:,j],alpha=0.9,lw=1)\n",
    "    if i == 0:\n",
    "        plt.legend(loc=1,ncols=4,frameon=True)\n",
    "    if i%gs.ncols != 0:\n",
    "        plt.tick_params(axis='y',labelleft=False,left=False)\n",
    "    else:\n",
    "        plt.ylabel('Value')\n",
    "    plt.xlabel('Time [days]')\n",
    "    plt.xlim(0.01,89.9)\n",
    "    plt.ylim(-0.59,0.6)\n",
    "\n",
    "out_file = 'trends_PCA.pdf'\n",
    "plt.savefig(out_file,bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04857b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined plot\n",
    "#Create a plot with the systematics of different cameras\n",
    "fig = plt.figure(1,figsize=(12,15))\n",
    "gs = gridspec.GridSpec(nrows=6,ncols=2)\n",
    "gs.update(hspace=0.025)\n",
    "gs.update(wspace=0.01)\n",
    "cameras = [0,1,2,3,4,5]\n",
    "colors=['C0','C1','C2','C3']\n",
    "#\n",
    "for i,cam in enumerate(cameras):\n",
    "    \n",
    "#\n",
    "    plt.subplot(gs[i*2])\n",
    "    for j in range(N):\n",
    "        if i == 0:\n",
    "            plt.plot(t,T_master[cam,:,j],alpha=0.9,label='Trend '+str(j+1),lw=1,ls='-',color=colors[j])\n",
    "        else:\n",
    "            plt.plot(t,T_master[cam,:,j],alpha=0.9,lw=1,ls='-',color=colors[j])\n",
    "        if i == 0:\n",
    "            plt.legend(loc=1,ncols=4,frameon=True)\n",
    "\n",
    "        plt.ylabel('Value')\n",
    "    \n",
    "    plt.xlabel('Time [days]')\n",
    "    plt.xlim(0.01,89.9)\n",
    "    plt.ylim(-0.59,0.6)\n",
    "#\n",
    "\n",
    "    plt.subplot(gs[i*2+1])\n",
    "    for j in range(N):\n",
    "        if i == 0:\n",
    "            plt.plot(t,T_CBV[cam,:,j],alpha=0.9,label='Trend '+str(j+1),lw=1,color=colors[j],ls='--')\n",
    "        else:\n",
    "            plt.plot(t,T_CBV[cam,:,j],alpha=0.9,lw=1,color=colors[j],ls='--')\n",
    "    if i == 0:\n",
    "        plt.legend(loc=1,ncols=4,frameon=True)\n",
    "\n",
    "    if i*2%gs.ncols == 0:\n",
    "        plt.tick_params(axis='y',labelleft=False,left=False)\n",
    "    else:\n",
    "        plt.ylabel('Value')\n",
    "        \n",
    "    plt.xlabel('Time [days]')\n",
    "    plt.xlim(0.01,89.9)\n",
    "    plt.ylim(-0.59,0.6)\n",
    "\n",
    "out_file = 'trends_PCA.pdf'\n",
    "plt.savefig(out_file,bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b8546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let us correct the light curves with this\n",
    "ncam=24\n",
    "for n in tqdm(range(N_l)):\n",
    "    T_use = T_CBV[:ncam,:,:] \n",
    "    sigma = np.zeros((ncam,K)) + sig\n",
    "    lcs[n].a_pca, lcs[n].w_pca, lcs[n].B_pca = republic.republic_solve(lcs[n].plato[:ncam], T_use, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc211ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlc = 0\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(lcs[nlc].a_pca)\n",
    "plt.plot(lcs[nlc].a_24)\n",
    "plt.plot(lcs[nlc].flux)\n",
    "plt.plot(lcs[nlc].plato[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5965367",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(lcs[nlc].a_pca-lcs[nlc].flux)\n",
    "plt.plot(lcs[nlc].a_24-lcs[nlc].flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ecfe6",
   "metadata": {},
   "source": [
    "### How the PDCLS behave with the imperfect trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#light curve by light curve\n",
    "for n in tqdm(range(N_l)):\n",
    "    lcs[n].pdcls_cbv = [None]*J\n",
    "    #camera by camera\n",
    "    for j in range(J):\n",
    "        #Let us shift the fluxes to zero to be able to do PDCLS \n",
    "        basis = np.array(T_CBV[j,:,:])\n",
    "        lcs[n].pdcls_cbv[j] = republic.PDCLS(lcs[n].plato[j]-np.mean(lcs[n].plato[j]),basis.T)\n",
    "    #Combine all the light curves \n",
    "    lcs[n].pdcls_mean_cbv = np.mean(lcs[n].pdcls_cbv,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(lcs[nlc].a_pca-lcs[nlc].flux)\n",
    "plt.plot(lcs[nlc].pdcls_mean_cbv-lcs[nlc].flux+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e47bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1,figsize=(14,7))\n",
    "gs = gridspec.GridSpec(nrows=2,ncols=1)\n",
    "gs.update(hspace=0.025)\n",
    "#\n",
    "plt.subplot(gs[0],rasterized=True)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].a_pca,'C1.',label='REPUBLIC with PCA',alpha=0.75)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].pdcls_mean_cbv+1,'C0.',label='PDCLS with PCA',alpha=0.75)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].flux,'k-',label='True signal')\n",
    "plt.xlim(lcs[nlc].time.min(),lcs[nlc].time.max())\n",
    "plt.tick_params(axis='x', which='both', direction='in',labelbottom=False)\n",
    "plt.ylabel('Flux')\n",
    "#\n",
    "plt.subplot(gs[1],rasterized=True)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].a_pca-lcs[nlc].flux,'C1.',label='REPUBLIC with PCA',alpha=0.75)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].pdcls_mean_cbv-lcs[nlc].flux+1,'C0.',label='PDCLS with PCA',alpha=0.75)\n",
    "plt.xlim(lcs[nlc].time.min(),lcs[nlc].time.max())\n",
    "plt.tick_params(axis='x', which='both', direction='in',labelbottom=True)\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylabel('Residuals')\n",
    "out_file = 'lc_nonidealcase.pdf'\n",
    "plt.savefig(out_file,bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed0a3e0",
   "metadata": {},
   "source": [
    "# Correlated trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7502c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create correlated trends\n",
    "#We will make that the first trend in all cameras is identical\n",
    "T_correlated = np.array(T_master)\n",
    "for i in range(1,J):\n",
    "    T_correlated[i,:,0] = T_master[0,:,0]\n",
    "\n",
    "\n",
    "    \n",
    "#Check visually that this works\n",
    "#\n",
    "#Create a plot with the systematics of different cameras\n",
    "fig = plt.figure(1,figsize=(15,10))\n",
    "gs = gridspec.GridSpec(nrows=3,ncols=2)\n",
    "gs.update(hspace=0.025)\n",
    "gs.update(wspace=0.01)\n",
    "cameras = [0,1,2,3,4,5]\n",
    "#\n",
    "\n",
    "for i,cam in enumerate(cameras):\n",
    "    plt.subplot(gs[i])\n",
    "    for j in range(N):\n",
    "        if i == 0:\n",
    "            plt.plot(t,T_correlated[cam,:,j],alpha=0.9,label='Trend '+str(j+1),lw=1)\n",
    "        else:\n",
    "            plt.plot(t,T_correlated[cam,:,j],alpha=0.9,lw=1)\n",
    "    if i == 0:\n",
    "        plt.legend(loc=1,ncols=4,frameon=True)\n",
    "    if i%gs.ncols != 0:\n",
    "        plt.tick_params(axis='y',labelleft=False,left=False)\n",
    "    else:\n",
    "        plt.ylabel('Value')\n",
    "    plt.xlabel('Time [days]')\n",
    "    plt.xlim(0.01,89.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbc5eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let us create PLATO light curves using these correlated systematics\n",
    "#We add a new attribute called plato_corr, similar to plato but with correlated systematics\n",
    "sig = 0.0005\n",
    "for i in tqdm(range(N_lcs)):\n",
    "    lcs[i].plato_corr = republic.platorize(lcs[i].flux,T_correlated,J,N,K,sig=sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a248ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let us apply republic to this\n",
    "#Run republic for 24 cameras\n",
    "for i in tqdm(range(N_l)):\n",
    "    #24 cameras\n",
    "    ncam=24\n",
    "    T_use = T_correlated[:ncam,:,:] \n",
    "    sigma = np.zeros((ncam,K)) + sig\n",
    "    lcs[i].a_corr, lcs[i].w_corr, lcs[i].B_corr = republic.republic_solve(lcs[i].plato_corr[0:ncam], T_use, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af2a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lcs[nlc].time,lcs[nlc].flux,'k-',label='True signal')\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].a_corr,'C3.',label='REPUBLIC $-$ True',alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7839ee",
   "metadata": {},
   "source": [
    "## Now we will use the PDC-like algorithm to correct with the correlated systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#light curve by light curve\n",
    "for n in tqdm(range(N_l)):\n",
    "    lcs[n].pdcls_corr = [None]*J\n",
    "    #camera by camera\n",
    "    for j in range(J):\n",
    "        #Let us shift the fluxes to zero to be able to do PDCLS \n",
    "        basis = np.array(T_correlated[j,:,:])\n",
    "        lcs[n].pdcls_corr[j] = republic.PDCLS(lcs[n].plato[j]-np.mean(lcs[n].plato_corr[j]),basis.T)\n",
    "    #Combine all the light curves \n",
    "    lcs[n].pdcls_mean_corr = np.mean(lcs[n].pdcls_corr,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08980ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(lcs[nlc].pdcls_mean_corr-lcs[nlc].flux+np.mean(lcs[nlc].flux))\n",
    "plt.plot(lcs[nlc].a_corr-lcs[nlc].flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18121e2",
   "metadata": {},
   "source": [
    "## Let us extract the correlated CBVs from the correlated case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014693d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_components = 4\n",
    "\n",
    "#Let us create an array to store the trends obtained with CBVs\n",
    "T_CBV_corr = np.ones((J,K,N_components)) \n",
    "\n",
    "#Here we need all the light curve N_lcs (not N_l) to extract the best CBVs\n",
    "data = [None]*N_lcs\n",
    "\n",
    "#camera by camera\n",
    "for j in tqdm(range(J)):\n",
    "    #light curve by light curve\n",
    "    for i in range(N_lcs):\n",
    "        data[i] = lcs[i].plato_corr[j]\n",
    "    #Now data has the information for all the light curves for a given camera\n",
    "    scaler = StandardScaler()\n",
    "    data_standardized = scaler.fit_transform(np.array(data).T)\n",
    "    #Apply PCA\n",
    "    pca = PCA()\n",
    "    pca_result = pca.fit_transform(data_standardized)\n",
    "    pca_components = PCA(n_components=N_components)\n",
    "    #extract the components\n",
    "    transformed_data = pca_components.fit_transform(data_standardized)\n",
    "    transformed_data_df = pd.DataFrame(transformed_data)\n",
    "    #Save the recovered PCA components in the T_CBV array to be used by republic\n",
    "    for k in range(N_components):\n",
    "        T_CBV_corr[j,:,k] = transformed_data_df[k] \n",
    "        T_CBV_corr[j,:,k] = (T_CBV_corr[j,:,k] - T_CBV_corr[j,:,k].min()) / (T_CBV_corr[j,:,k].max() - T_CBV_corr[j,:,k].min()) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c26ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a plot with the systematics of different cameras\n",
    "fig = plt.figure(1,figsize=(15,10))\n",
    "gs = gridspec.GridSpec(nrows=3,ncols=2)\n",
    "gs.update(hspace=0.025)\n",
    "gs.update(wspace=0.01)\n",
    "cameras = [0,1,2,3,4,5]\n",
    "#\n",
    "\n",
    "for i,cam in enumerate(cameras):\n",
    "    plt.subplot(gs[i])\n",
    "    for j in range(N):\n",
    "        if i == 0:\n",
    "            plt.plot(t,T_CBV_corr[cam,:,j],alpha=0.9,label='Trend '+str(j+1),lw=1)\n",
    "        else:\n",
    "            plt.plot(t,T_CBV_corr[cam,:,j],alpha=0.9,lw=1)\n",
    "    if i%gs.ncols != 0:\n",
    "        plt.tick_params(axis='y',labelleft=False,left=False)\n",
    "    else:\n",
    "        plt.ylabel('Value')\n",
    "    plt.xlabel('Time [days]')\n",
    "    plt.xlim(0.01,89.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let us apply republic to this\n",
    "#Run republic for 24 cameras\n",
    "for i in tqdm(range(N_l)):\n",
    "    #24 cameras\n",
    "    ncam=24\n",
    "    T_use = T_CBV_corr[:ncam,:,:] \n",
    "    sigma = np.zeros((ncam,K)) + sig\n",
    "    lcs[i].a_corr_cbv, lcs[i].w_corr_cbv, lcs[i].B_corr_cbv = republic.republic_solve(lcs[i].plato_corr[0:ncam], T_use, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a60fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lcs[nlc].time,lcs[nlc].flux,'k-',label='True signal')\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].a_corr_cbv,'C3.',label='REPUBLIC $-$ True',alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f10f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lcs[nlc].time,lcs[nlc].a_corr_cbv-lcs[nlc].flux,'C3.',label='REPUBLIC $-$ True',alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a982994e",
   "metadata": {},
   "source": [
    "### LET's make the plot of the correlated trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a196be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined plot\n",
    "#Create a plot with the systematics of different cameras\n",
    "fig = plt.figure(1,figsize=(12,15))\n",
    "gs = gridspec.GridSpec(nrows=6,ncols=2)\n",
    "gs.update(hspace=0.025)\n",
    "gs.update(wspace=0.01)\n",
    "cameras = [0,1,2,3,4,5]\n",
    "colors=['C0','C1','C2','C3']\n",
    "#\n",
    "for i,cam in enumerate(cameras):\n",
    "    \n",
    "#\n",
    "    plt.subplot(gs[i*2])\n",
    "    for j in range(N):\n",
    "        if i == 0:\n",
    "            plt.plot(t,T_correlated[cam,:,j],alpha=0.9,label='Trend '+str(j+1),lw=1,ls='-',color=colors[j])\n",
    "        else:\n",
    "            plt.plot(t,T_correlated[cam,:,j],alpha=0.9,lw=1,ls='-',color=colors[j])\n",
    "        if i == 0:\n",
    "            plt.legend(loc=1,ncols=4,frameon=True)\n",
    "\n",
    "        plt.ylabel('Value')\n",
    "    \n",
    "    plt.xlabel('Time [days]')\n",
    "    plt.xlim(0.01,89.9)\n",
    "    plt.ylim(-0.59,0.6)\n",
    "#\n",
    "\n",
    "    plt.subplot(gs[i*2+1])\n",
    "    for j in range(N):\n",
    "        if i == 0:\n",
    "            plt.plot(t,T_CBV_corr[cam,:,j],alpha=0.9,label='Trend '+str(j+1),lw=1,color=colors[j],ls='--')\n",
    "        else:\n",
    "            plt.plot(t,T_CBV_corr[cam,:,j],alpha=0.9,lw=1,color=colors[j],ls='--')\n",
    "    if i == 0:\n",
    "        plt.legend(loc=1,ncols=4,frameon=True)\n",
    "\n",
    "    if i*2%gs.ncols == 0:\n",
    "        plt.tick_params(axis='y',labelleft=False,left=False)\n",
    "    else:\n",
    "        plt.ylabel('Value')\n",
    "        \n",
    "    plt.xlabel('Time [days]')\n",
    "    plt.xlim(0.01,89.9)\n",
    "    plt.ylim(-0.59,0.6)\n",
    "\n",
    "out_file = 'trends_correlated.pdf'\n",
    "plt.savefig(out_file,bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1,figsize=(14,7))\n",
    "gs = gridspec.GridSpec(nrows=2,ncols=1)\n",
    "gs.update(hspace=0.025)\n",
    "#\n",
    "plt.subplot(gs[0],rasterized=True)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].a_corr_cbv,'C0.',label='REPUBLIC with PCA',alpha=0.75)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].pdcls_mean_corr+1,'C1.',label='PDCLS with PCA',alpha=0.75)\n",
    "\n",
    "\n",
    "#NEED TO ADD CODE TOCOMPUTE THE LS CORRECTION\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].flux,'k-',label='True signal')\n",
    "plt.xlim(lcs[nlc].time.min(),lcs[nlc].time.max())\n",
    "plt.tick_params(axis='x', which='both', direction='in',labelbottom=False)\n",
    "plt.ylabel('Flux')\n",
    "#\n",
    "plt.subplot(gs[1],rasterized=True)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].a_corr_cbv-lcs[nlc].flux,'C0.',label='REPUBLIC with PCA',alpha=0.75)\n",
    "plt.plot(lcs[nlc].time,lcs[nlc].pdcls_mean_corr-lcs[nlc].flux+1,'C1.',label='PDCLS with PCA',alpha=0.75)\n",
    "plt.xlim(lcs[nlc].time.min(),lcs[nlc].time.max())\n",
    "plt.tick_params(axis='x', which='both', direction='in',labelbottom=True)\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylabel('Residuals')\n",
    "out_file = 'lc_correlated.pdf'\n",
    "plt.savefig(out_file,bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e541f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
